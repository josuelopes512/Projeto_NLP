{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### VISÃO GERAL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma empresa contratante deseja estabelecer termos de maior relevância em um documento\n",
    "específico. Neste caso, considere o histórico de exames, consultas e procedimentos realizados\n",
    "por um paciente. Um sistema deve ser desenvolvido para que o médico possa ter uma visão\n",
    "geral do histórico do paciente sem a necessidade de analisar documento por documento. Com\n",
    "base nesta importância, vamos desenvolver uma etapa deste sistema. Tokenizar um texto,\n",
    "realizar remoção de stopwords, aplicar o processo de lematização e fazer uma análise\n",
    "quantitativa e visual subjetiva deste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OBJETIVOS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Carregar o conjunto de documentos em PDF e armazená-los em alguma estrutura de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Realizar o pré-processamento destes ( tokenização e remoção de stop words, deixar todos os\n",
    "caracteres minúsculos...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Lematização com a Lib stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Implementar para determinar as seguintes informações dos resultados obtidos em 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. <br>  1. Term Frequency (TF):\n",
    "<br> 𝑇𝐹 = 𝑞𝑡𝑑 𝑑𝑒 𝑜𝑐𝑜𝑟𝑟ê𝑛𝑐𝑖𝑎 𝑑𝑜 𝑡𝑒𝑟𝑚𝑜 𝑒𝑚 𝑢𝑚 𝑡𝑒𝑥𝑡𝑜 / 𝑞𝑢𝑎𝑛𝑡𝑖𝑑𝑎𝑑𝑒 𝑡𝑜𝑡𝑎𝑙 𝑑𝑒 𝑝𝑎𝑙𝑎𝑣𝑟𝑎𝑠 𝑑𝑜 𝑡𝑒𝑥𝑡𝑜\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. <br>  2. Document Frequency (DF):\n",
    "<br> 𝐷𝐹 = 𝑞𝑡𝑑 𝑑𝑒 𝑜𝑐𝑜𝑟𝑟ê𝑛𝑐𝑖𝑎 𝑑𝑜 𝑡𝑒𝑟𝑚𝑜 𝑒𝑚 𝑢𝑚 𝑐𝑜𝑛𝑗𝑢𝑛𝑡𝑜 𝑑𝑒 𝑑𝑜𝑐𝑢𝑚𝑒𝑛𝑡𝑜𝑠\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. <br>  3. Inverse Document Frequency (IDF):\n",
    "<br> 𝐼𝐷𝐹 = 𝑙𝑜𝑔(𝑞𝑡𝑑 𝑑𝑒 𝑑𝑜𝑐𝑢𝑚𝑒𝑛𝑡𝑜𝑠 / (𝐷𝐹 + 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. <br>  4. TF-IDF:\n",
    "<br> 𝑇𝐹 − 𝐼𝐷𝐹 = 𝐼𝐷𝐹 * 𝑇𝐹\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. <br>  5. Lista de strings com proximidade até 2 dos 5 termos de maior TF-IDF. Essas strings\n",
    "devem ser acompanhadas de seu valor de TF. Exemplo: Suponha que a lista dos 5 termos de maior TF-IDF é [ casa, carro, comida, cachorro, gato]. Carro em um uma frase pode ter pneu e\n",
    "banco com as palavras mais próximas. Em outra parte do texto, carro pode ter volante e cinto,\n",
    "como as palavras mais próximas. Neste caso, para o termo carro, as strings [\n",
    "pneu,banco,volante,cinto] são as que devem ser armazenadas para análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Gerar um arquivo csv que possui todas as palavras de todos os documentos na primeira coluna,\n",
    "em que cada linha é um token. Para cada token, informe nas colunas vizinhas as informações\n",
    "determinadas no objetivo 4.1 até 4.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Gerar nuvem de palavras para análise visual tal como exemplo abaixo. Cada ponto central será\n",
    "um dos 5 termos de maior TF-IDF. As conexões são as palavras próximas obtidas em 4.5. O\n",
    "tamanho do círculo da palavra é baseado no TF dela. O maior círculo que conecta o termo\n",
    "central será normalizado para palavras de maior TF do conjunto.\n",
    "![MarineGEO circle logo](https://i.imgur.com/gNv4V7l.png \"MarineGEO logo\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tópicos de Auxílio\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "Informações sobre as métricas utilizadas\n",
    "<br>\n",
    "https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089\n",
    "<br>\n",
    "<br>\n",
    "Atividade determinação da nuvem de palavras\n",
    "<br>\n",
    "https://www.kaggle.com/code/arthurtok/ghastly-network-and-d3-js-force-directed-graphs/notebook\n",
    "<br>\n",
    "http://andrewtrick.com/stormlight_network.html"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96068ab639a04010ce0ebf4d92aa5fa1d95945955db043eb093ed651d9ac7c11"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
