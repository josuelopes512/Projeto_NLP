{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### VISÃƒO GERAL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma empresa contratante deseja estabelecer termos de maior relevÃ¢ncia em um documento\n",
    "especÃ­fico. Neste caso, considere o histÃ³rico de exames, consultas e procedimentos realizados\n",
    "por um paciente. Um sistema deve ser desenvolvido para que o mÃ©dico possa ter uma visÃ£o\n",
    "geral do histÃ³rico do paciente sem a necessidade de analisar documento por documento. Com\n",
    "base nesta importÃ¢ncia, vamos desenvolver uma etapa deste sistema. Tokenizar um texto,\n",
    "realizar remoÃ§Ã£o de stopwords, aplicar o processo de lematizaÃ§Ã£o e fazer uma anÃ¡lise\n",
    "quantitativa e visual subjetiva deste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OBJETIVOS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Carregar o conjunto de documentos em PDF e armazenÃ¡-los em alguma estrutura de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Realizar o prÃ©-processamento destes ( tokenizaÃ§Ã£o e remoÃ§Ã£o de stop words, deixar todos os\n",
    "caracteres minÃºsculos...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. LematizaÃ§Ã£o com a Lib stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Implementar para determinar as seguintes informaÃ§Ãµes dos resultados obtidos em 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. <br>  1. Term Frequency (TF):\n",
    "<br> ğ‘‡ğ¹ = ğ‘ğ‘¡ğ‘‘ ğ‘‘ğ‘’ ğ‘œğ‘ğ‘œğ‘Ÿğ‘ŸÃªğ‘›ğ‘ğ‘–ğ‘ ğ‘‘ğ‘œ ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘œ ğ‘’ğ‘š ğ‘¢ğ‘š ğ‘¡ğ‘’ğ‘¥ğ‘¡ğ‘œ / ğ‘ğ‘¢ğ‘ğ‘›ğ‘¡ğ‘–ğ‘‘ğ‘ğ‘‘ğ‘’ ğ‘¡ğ‘œğ‘¡ğ‘ğ‘™ ğ‘‘ğ‘’ ğ‘ğ‘ğ‘™ğ‘ğ‘£ğ‘Ÿğ‘ğ‘  ğ‘‘ğ‘œ ğ‘¡ğ‘’ğ‘¥ğ‘¡ğ‘œ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. <br>  2. Document Frequency (DF):\n",
    "<br> ğ·ğ¹ = ğ‘ğ‘¡ğ‘‘ ğ‘‘ğ‘’ ğ‘œğ‘ğ‘œğ‘Ÿğ‘ŸÃªğ‘›ğ‘ğ‘–ğ‘ ğ‘‘ğ‘œ ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘œ ğ‘’ğ‘š ğ‘¢ğ‘š ğ‘ğ‘œğ‘›ğ‘—ğ‘¢ğ‘›ğ‘¡ğ‘œ ğ‘‘ğ‘’ ğ‘‘ğ‘œğ‘ğ‘¢ğ‘šğ‘’ğ‘›ğ‘¡ğ‘œğ‘ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. <br>  3. Inverse Document Frequency (IDF):\n",
    "<br> ğ¼ğ·ğ¹ = ğ‘™ğ‘œğ‘”(ğ‘ğ‘¡ğ‘‘ ğ‘‘ğ‘’ ğ‘‘ğ‘œğ‘ğ‘¢ğ‘šğ‘’ğ‘›ğ‘¡ğ‘œğ‘  / (ğ·ğ¹ + 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. <br>  4. TF-IDF:\n",
    "<br> ğ‘‡ğ¹ âˆ’ ğ¼ğ·ğ¹ = ğ¼ğ·ğ¹ * ğ‘‡ğ¹\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. <br>  5. Lista de strings com proximidade atÃ© 2 dos 5 termos de maior TF-IDF. Essas strings\n",
    "devem ser acompanhadas de seu valor de TF. Exemplo: Suponha que a lista dos 5 termos de maior TF-IDF Ã© [ casa, carro, comida, cachorro, gato]. Carro em um uma frase pode ter pneu e\n",
    "banco com as palavras mais prÃ³ximas. Em outra parte do texto, carro pode ter volante e cinto,\n",
    "como as palavras mais prÃ³ximas. Neste caso, para o termo carro, as strings [\n",
    "pneu,banco,volante,cinto] sÃ£o as que devem ser armazenadas para anÃ¡lise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Gerar um arquivo csv que possui todas as palavras de todos os documentos na primeira coluna,\n",
    "em que cada linha Ã© um token. Para cada token, informe nas colunas vizinhas as informaÃ§Ãµes\n",
    "determinadas no objetivo 4.1 atÃ© 4.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Gerar nuvem de palavras para anÃ¡lise visual tal como exemplo abaixo. Cada ponto central serÃ¡\n",
    "um dos 5 termos de maior TF-IDF. As conexÃµes sÃ£o as palavras prÃ³ximas obtidas em 4.5. O\n",
    "tamanho do cÃ­rculo da palavra Ã© baseado no TF dela. O maior cÃ­rculo que conecta o termo\n",
    "central serÃ¡ normalizado para palavras de maior TF do conjunto.\n",
    "![MarineGEO circle logo](https://i.imgur.com/gNv4V7l.png \"MarineGEO logo\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TÃ³picos de AuxÃ­lio\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "InformaÃ§Ãµes sobre as mÃ©tricas utilizadas\n",
    "<br>\n",
    "https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089\n",
    "<br>\n",
    "<br>\n",
    "Atividade determinaÃ§Ã£o da nuvem de palavras\n",
    "<br>\n",
    "https://www.kaggle.com/code/arthurtok/ghastly-network-and-d3-js-force-directed-graphs/notebook\n",
    "<br>\n",
    "http://andrewtrick.com/stormlight_network.html"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96068ab639a04010ce0ebf4d92aa5fa1d95945955db043eb093ed651d9ac7c11"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
